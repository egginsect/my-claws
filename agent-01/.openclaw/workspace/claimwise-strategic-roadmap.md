# Claimwise Strategic Improvement Roadmap

**Document Type:** Architectural Strategy & Prioritization  
**Author:** Strategic Planning Agent (Opus-level analysis)  
**Date:** 2026-02-05  
**Input Sources:** Comprehensive QA Report, Codebase Analysis, Market Research

---

## Executive Summary

Claimwise has strong product-market fit potential but faces **critical technical debt** that blocks go-to-market. This roadmap outlines a **3-phase approach** to transform Claimwise from a prototype into a production-ready, scalable platform.

**Strategic Goals:**
1. âœ… **Unblock Production** (Phase 1: 1-2 weeks)
2. ğŸš€ **Enable Scale** (Phase 2: 3-4 weeks)
3. ğŸ¯ **Differentiate & Monetize** (Phase 3: 8-12 weeks)

---

## Phase 1: Foundation (Weeks 1-2) - CRITICAL PATH

**Goal:** Make the application functional and deployable

### 1.1 Build System Rescue âš ï¸ BLOCKER

**Problem:** Webpack cannot process Tailwind CSS directives

**Strategic Approach: Upgrade First, Debug Second**

Don't try to fix Next.js 14.2 + Tailwind 3.3 compatibility issues. Move forward to battle-tested versions.

**Action Plan:**
```bash
# Step 1: Upgrade to latest stable
yarn upgrade next@15.1.0 tailwindcss@3.4.15 postcss@8.4.47 autoprefixer@10.4.20

# Step 2: Update React to 19 (Next 15 requirement)
yarn upgrade react@19 react-dom@19 @types/react@19 @types/react-dom@19

# Step 3: Test build
yarn build
```

**Fallback Strategy (if upgrade breaks):**
1. Use CSS-in-JS (styled-components or Emotion) instead of Tailwind
2. Pre-compile Tailwind separately using CLI
3. Use vanilla CSS with CSS modules

**Success Criteria:**
- âœ… `yarn dev` starts without errors
- âœ… All routes load correctly
- âœ… Tailwind styles render
- âœ… `yarn build` completes successfully

**Estimated Time:** 4-8 hours  
**Owner:** Senior Frontend Engineer  
**Risk:** Medium (upgrade may introduce new issues)

---

### 1.2 API Health & Monitoring

**Problem:** No reliable health checks for deployment platforms

**Solution: Standardized Health Endpoints**

```python
# api/health.py
from fastapi import FastAPI, Response
from datetime import datetime
import httpx

app = FastAPI()

@app.get("/health")
async def health_basic():
    """Basic liveness check"""
    return {"status": "ok", "timestamp": datetime.utcnow().isoformat()}

@app.get("/health/ready")
async def health_ready():
    """Readiness check with dependency validation"""
    checks = {
        "supabase": await check_supabase(),
        "openai": await check_openai(),
    }
    
    all_healthy = all(checks.values())
    status_code = 200 if all_healthy else 503
    
    return Response(
        content=json.dumps({
            "status": "ready" if all_healthy else "degraded",
            "checks": checks,
            "timestamp": datetime.utcnow().isoformat()
        }),
        status_code=status_code,
        media_type="application/json"
    )

async def check_supabase():
    try:
        async with httpx.AsyncClient() as client:
            response = await client.get(
                f"{os.getenv('SUPABASE_URL')}/rest/v1/",
                timeout=5.0
            )
            return response.status_code < 500
    except:
        return False
```

**Deployment Configuration:**
```yaml
# vercel.json
{
  "headers": [
    {
      "source": "/api/(.*)",
      "headers": [
        {
          "key": "Cache-Control",
          "value": "no-store, must-revalidate"
        }
      ]
    }
  ],
  "rewrites": [
    {
      "source": "/api/mcp/:path*",
      "destination": "/api/mcp.py"
    }
  ],
  "healthCheck": {
    "path": "/api/health"
  }
}
```

**Success Criteria:**
- âœ… `/api/health` returns 200 with JSON payload
- âœ… `/api/health/ready` validates all dependencies
- âœ… Vercel/Railway deployment health checks pass

**Estimated Time:** 2-3 hours  
**Owner:** Backend Engineer

---

### 1.3 Security Hardening (MVP Level)

**Problem:** No rate limiting, insufficient input validation

**Solution: Progressive Security Layers**

**Layer 1: Rate Limiting (IMMEDIATE)**
```python
# api/middleware/rate_limit.py
from slowapi import Limiter
from slowapi.util import get_remote_address

limiter = Limiter(
    key_func=get_remote_address,
    default_limits=["100/hour"],
    storage_uri="memory://"  # Use Redis in production
)

# Apply to endpoints
@app.post("/rest/tools/call")
@limiter.limit("30/minute")
async def call_tool(request: Request):
    ...
```

**Layer 2: Input Validation (IMMEDIATE)**
```python
# api/validation.py
from pydantic import BaseModel, Field, validator
import re

class ClaimQuestionInput(BaseModel):
    question: str = Field(..., min_length=3, max_length=2000)
    claim_id: str | None = Field(None, regex=r'^[a-f0-9-]{36}$')
    
    @validator('question')
    def sanitize_question(cls, v):
        # Remove control characters
        v = re.sub(r'[\x00-\x1f\x7f-\x9f]', '', v)
        # Basic XSS prevention
        v = v.replace('<script>', '').replace('</script>', '')
        return v.strip()
```

**Layer 3: CSRF Protection (HIGH PRIORITY)**
```typescript
// lib/api/csrf.ts
export async function getCsrfToken(): Promise<string> {
  const response = await fetch('/api/csrf');
  const { token } = await response.json();
  return token;
}

export async function callToolWithCsrf(name: string, args: any) {
  const token = await getCsrfToken();
  return fetch('/api/mcp/rest/tools/call', {
    method: 'POST',
    headers: {
      'Content-Type': 'application/json',
      'X-CSRF-Token': token,
    },
    body: JSON.stringify({ name, arguments: args }),
  });
}
```

**Success Criteria:**
- âœ… Rate limiting blocks excessive requests
- âœ… Invalid inputs rejected with clear errors
- âœ… CSRF tokens required for all write operations

**Estimated Time:** 1 day  
**Owner:** Security + Backend Team

---

## Phase 2: Scale Preparation (Weeks 3-4)

**Goal:** Handle production traffic and maintain reliability

### 2.1 Observability Stack

**Problem:** No visibility into production issues

**Solution: Structured Logging + Metrics + Tracing**

**Logging:**
```python
# api/logging_config.py
import logging
import json
from datetime import datetime

class StructuredLogger:
    def __init__(self, name: str):
        self.logger = logging.getLogger(name)
        self.logger.setLevel(logging.INFO)
    
    def log_event(self, event: str, **kwargs):
        log_entry = {
            "timestamp": datetime.utcnow().isoformat(),
            "event": event,
            "service": "claimwise-mcp",
            **kwargs
        }
        self.logger.info(json.dumps(log_entry))

logger = StructuredLogger("claimwise")

# Usage
logger.log_event(
    "tool_execution",
    tool="answer_claim_question",
    user_id=user_id,
    duration_ms=elapsed_ms,
    success=True
)
```

**Metrics (Prometheus-compatible):**
```python
# api/metrics.py
from prometheus_client import Counter, Histogram, generate_latest

tool_executions = Counter(
    'claimwise_tool_executions_total',
    'Total tool executions',
    ['tool_name', 'status']
)

tool_duration = Histogram(
    'claimwise_tool_duration_seconds',
    'Tool execution duration',
    ['tool_name']
)

@app.get("/metrics")
async def metrics():
    return Response(content=generate_latest(), media_type="text/plain")
```

**Distributed Tracing (Optional):**
```python
# api/tracing.py
from opentelemetry import trace
from opentelemetry.exporter.otlp.proto.http.trace_exporter import OTLPSpanExporter
from opentelemetry.sdk.trace import TracerProvider

tracer_provider = TracerProvider()
trace.set_tracer_provider(tracer_provider)
tracer = trace.get_tracer(__name__)

@tracer.start_as_current_span("tool_execution")
async def execute_tool(tool_name: str, args: dict):
    span = trace.get_current_span()
    span.set_attribute("tool.name", tool_name)
    ...
```

**Dashboard Setup:**
- Use Vercel Analytics for frontend metrics
- Use Axiom/Datadog/New Relic for backend logs
- Set up alerts for error rates > 5%

**Success Criteria:**
- âœ… All API calls logged with structured JSON
- âœ… P95 latency visible in dashboard
- âœ… Error rate alerts configured
- âœ… Traces available for debugging

**Estimated Time:** 3-4 days  
**Owner:** DevOps + Backend Team

---

### 2.2 Performance Optimization

**Problem:** Slow responses due to sequential operations

**Solution: Parallel Execution + Caching**

**Parallel Database Queries:**
```python
# Before: 500-800ms (sequential)
policies = await search_policies_vector(user_id, query)
transactions = await search_transactions_vector(user_id, query)
emails = await search_emails_vector(user_id, query)

# After: 200-300ms (parallel)
import asyncio

results = await asyncio.gather(
    search_policies_vector(user_id, query),
    search_transactions_vector(user_id, query),
    search_emails_vector(user_id, query),
    return_exceptions=True  # Don't fail if one query fails
)

policies, transactions, emails = [
    r if not isinstance(r, Exception) else []
    for r in results
]
```

**Redis Caching Layer:**
```python
# api/cache.py
import redis.asyncio as redis
import json
from typing import Any, Optional

class Cache:
    def __init__(self):
        self.redis = redis.from_url(
            os.getenv("REDIS_URL", "redis://localhost:6379"),
            decode_responses=True
        )
    
    async def get(self, key: str) -> Optional[dict]:
        data = await self.redis.get(key)
        return json.loads(data) if data else None
    
    async def set(self, key: str, value: dict, ttl: int = 300):
        await self.redis.setex(key, ttl, json.dumps(value))
    
    def cache_key(self, prefix: str, **kwargs) -> str:
        sorted_args = sorted(kwargs.items())
        return f"{prefix}:{':'.join(f'{k}={v}' for k, v in sorted_args)}"

cache = Cache()

# Usage
async def get_user_coverage_context(user_id: str):
    cache_key = cache.cache_key("coverage", user_id=user_id)
    cached = await cache.get(cache_key)
    if cached:
        return cached
    
    context = await load_user_coverage_context(user_id)
    await cache.set(cache_key, context, ttl=600)  # Cache for 10 minutes
    return context
```

**Database Indexing:**
```sql
-- supabase/migrations/add_performance_indexes.sql

-- Vector search optimization
CREATE INDEX idx_policy_embeddings_user ON policy_documents(user_id);
CREATE INDEX idx_transaction_embeddings_user ON transactions(user_id);

-- Coverage context queries
CREATE INDEX idx_card_coverages_user ON card_coverages(user_id);
CREATE INDEX idx_cards_user_active ON cards(user_id) WHERE active = true;

-- Date range queries
CREATE INDEX idx_transactions_user_date ON transactions(user_id, posted_date DESC);
CREATE INDEX idx_claims_user_created ON claims(user_id, created_at DESC);
```

**Success Criteria:**
- âœ… P95 response time < 500ms (from 2-5s)
- âœ… Cache hit rate > 60%
- âœ… Database query time < 100ms

**Estimated Time:** 1 week  
**Owner:** Backend + Database Team

---

### 2.3 Frontend Performance

**Problem:** Large bundle size, slow initial load

**Solution: Code Splitting + Image Optimization**

**Code Splitting:**
```typescript
// app/(app)/claims/page.tsx
import dynamic from 'next/dynamic';

// Lazy load heavy components
const ClaimDetailsModal = dynamic(() => import('@/components/claims/ClaimDetailsModal'));
const CoverageChat = dynamic(() => import('@/components/chat/CoverageChat'), {
  loading: () => <ChatSkeleton />,
  ssr: false  // Don't render on server
});

// Split by route
const AdminPanel = dynamic(() => import('@/app/(app)/admin/AdminPanel'), {
  ssr: false
});
```

**Image Optimization:**
```tsx
// Use Next.js Image component
import Image from 'next/image';

<Image
  src="/images/title-card.png"
  alt="Claimwise workspace"
  width={1200}
  height={630}
  priority  // Load immediately for above-fold images
/>

// Use WebP/AVIF formats
// next.config.mjs
export default {
  images: {
    formats: ['image/avif', 'image/webp'],
  },
};
```

**Bundle Analysis:**
```json
// package.json
{
  "scripts": {
    "analyze": "ANALYZE=true yarn build"
  }
}
```

**Success Criteria:**
- âœ… First Contentful Paint < 1.5s
- âœ… Time to Interactive < 3s
- âœ… Bundle size < 500KB (gzipped)
- âœ… Lighthouse score > 90

**Estimated Time:** 3-4 days  
**Owner:** Frontend Team

---

## Phase 3: Differentiation (Weeks 5-12)

**Goal:** Build features that create competitive moat

### 3.1 Real-time Claim Tracking

**Problem:** Users don't know claim status without manual checking

**Solution: Event-driven Status Updates**

**Architecture:**
```
User â†’ Carrier Portal â†’ Webhook â†’ Supabase Function â†’ Realtime Channel â†’ Frontend
```

**Implementation:**
```typescript
// lib/realtime/claims.ts
import { createClient } from '@/lib/supabase/client';

export function useClaimUpdates(userId: string) {
  const supabase = createClient();
  
  useEffect(() => {
    const channel = supabase
      .channel(`claims:${userId}`)
      .on(
        'postgres_changes',
        {
          event: 'UPDATE',
          schema: 'public',
          table: 'claims',
          filter: `user_id=eq.${userId}`,
        },
        (payload) => {
          // Show notification
          toast.success(`Claim ${payload.new.id} updated to ${payload.new.status}`);
          // Update UI
          queryClient.invalidateQueries(['claims']);
        }
      )
      .subscribe();
    
    return () => {
      supabase.removeChannel(channel);
    };
  }, [userId]);
}
```

**Success Criteria:**
- âœ… Real-time updates arrive < 1 second
- âœ… Notifications show in-app and push
- âœ… No polling required

**Estimated Time:** 1-2 weeks  
**Owner:** Full-stack Team

---

### 3.2 Proactive Coverage Recommendations

**Problem:** Users reactive (file after incident) not proactive

**Solution: AI-powered Transaction Monitoring**

**Architecture:**
```
Plaid Webhook â†’ Parse Transaction â†’ Check Coverage â†’ Suggest Card â†’ Notify User
```

**Implementation:**
```python
# api/services/proactive_recommendations.py
async def analyze_upcoming_purchase(transaction: dict, user_id: str):
    """Run when user makes large purchase"""
    
    # Check if better card available
    current_card_id = transaction['card_id']
    merchant = transaction['merchant_name']
    amount = transaction['amount']
    
    # Get user's other cards
    user_cards = await get_user_cards(user_id)
    
    # Analyze coverage for this merchant/category
    coverage_analysis = await analyze_coverage_for_purchase(
        merchant=merchant,
        amount=amount,
        category=transaction['category'],
        cards=user_cards
    )
    
    # If better option exists, notify user
    if coverage_analysis['recommended_card_id'] != current_card_id:
        await send_notification(
            user_id=user_id,
            title="Better card for this purchase!",
            message=f"Using {coverage_analysis['recommended_card_name']} would give you {coverage_analysis['benefit_summary']}",
            action_url=f"/cards/{coverage_analysis['recommended_card_id']}"
        )
```

**ML Model (Future Enhancement):**
```python
# Train model to predict claim likelihood
import pandas as pd
from sklearn.ensemble import RandomForestClassifier

def train_claim_prediction_model():
    # Features: merchant, amount, category, card, user purchase history
    # Label: claim_filed (boolean)
    
    df = load_historical_claims_data()
    X = df[['merchant_category', 'amount', 'card_type', 'user_claim_rate']]
    y = df['claim_filed']
    
    model = RandomForestClassifier()
    model.fit(X, y)
    
    return model

# Use model to predict high-risk transactions
def predict_claim_risk(transaction: dict) -> float:
    model = load_model('claim_prediction_v1')
    features = extract_features(transaction)
    return model.predict_proba([features])[0][1]  # Probability of claim
```

**Success Criteria:**
- âœ… Recommendations sent within 5 minutes of transaction
- âœ… Recommendation accuracy > 70%
- âœ… User engagement rate > 15%

**Estimated Time:** 3-4 weeks  
**Owner:** ML + Backend Team

---

### 3.3 Multi-card Optimization Engine

**Problem:** Users with 5+ cards don't know which to use

**Solution: "Smart Wallet" feature

**Implementation:**
```typescript
// components/smart-wallet/CardRecommendation.tsx
export function CardRecommendationWidget() {
  const [scenario, setScenario] = useState('');
  const [recommendation, setRecommendation] = useState(null);
  
  async function getRecommendation() {
    const response = await fetch('/api/mcp/rest/tools/call', {
      method: 'POST',
      body: JSON.stringify({
        name: 'suggest_best_card',
        arguments: {
          scenario,
          is_travel: scenario.includes('flight') || scenario.includes('hotel')
        }
      })
    });
    
    const data = await response.json();
    setRecommendation(data.result);
  }
  
  return (
    <div className="card">
      <h3>Which card should I use?</h3>
      <input
        type="text"
        placeholder="e.g., booking a $2,000 flight to Japan"
        value={scenario}
        onChange={(e) => setScenario(e.target.value)}
      />
      <button onClick={getRecommendation}>Get Recommendation</button>
      
      {recommendation && (
        <RecommendationResult
          card={recommendation.recommended_card}
          reason={recommendation.reasoning}
          alternatives={recommendation.alternatives}
        />
      )}
    </div>
  );
}
```

**Browser Extension (Future):**
```javascript
// Chrome extension that auto-suggests card at checkout
chrome.runtime.onMessage.addListener((request, sender, sendResponse) => {
  if (request.type === 'CHECKOUT_DETECTED') {
    const amount = extractAmountFromPage();
    const merchant = extractMerchantFromPage();
    
    fetch('https://api.claimwise.ai/v1/recommend', {
      method: 'POST',
      body: JSON.stringify({ amount, merchant })
    })
      .then(res => res.json())
      .then(data => {
        showRecommendationOverlay(data.recommended_card);
      });
  }
});
```

**Success Criteria:**
- âœ… Recommendation provided < 2 seconds
- âœ… 80%+ recommendation accuracy
- âœ… Users adopt recommended card 40%+ of time

**Estimated Time:** 2-3 weeks  
**Owner:** Product + Full-stack Team

---

### 3.4 Automated Claim Filing

**Problem:** Filing claims is tedious (collect receipts, fill forms, upload docs)

**Solution: One-click claim initiation with auto-populated forms

**Architecture:**
```
Transaction â†’ Extract Metadata â†’ Find Relevant Documents â†’ Pre-fill Claim Form â†’ User Reviews â†’ Submit to Carrier
```

**Implementation:**
```python
# api/services/auto_claim.py
async def prepare_claim_submission(claim_id: str, user_id: str):
    """Prepare all documents and forms for claim submission"""
    
    claim = await get_claim_by_id(claim_id, user_id)
    transaction = await get_transaction_by_id(claim['transaction_id'], user_id)
    
    # Find relevant documents
    documents = await find_relevant_documents(
        user_id=user_id,
        merchant=transaction['merchant_name'],
        date=transaction['posted_date'],
        amount=transaction['amount']
    )
    
    # Extract metadata from documents (receipts, invoices)
    extracted_data = await extract_metadata_from_documents(documents)
    
    # Get carrier claim form template
    card = await get_card_by_id(claim['card_id'], user_id)
    form_template = await get_carrier_form_template(card['issuer'])
    
    # Auto-fill form
    filled_form = auto_fill_claim_form(
        template=form_template,
        transaction=transaction,
        extracted_data=extracted_data,
        claim=claim
    )
    
    return {
        "form": filled_form,
        "supporting_documents": documents,
        "submission_ready": True
    }
```

**Carrier Integration:**
```python
# api/integrations/carriers/chase.py
class ChaseClaimSubmitter:
    async def submit_claim(self, claim_data: dict, user_credentials: dict):
        """Submit claim to Chase via automated browser or API"""
        
        # Option 1: API (if available)
        if self.has_api_access():
            return await self.submit_via_api(claim_data)
        
        # Option 2: Automated browser (Playwright)
        async with async_playwright() as p:
            browser = await p.chromium.launch(headless=True)
            page = await browser.new_page()
            
            # Navigate to claims portal
            await page.goto('https://www.chase.com/claims')
            
            # Login (using user credentials securely stored)
            await page.fill('#username', user_credentials['username'])
            await page.fill('#password', decrypt(user_credentials['encrypted_password']))
            await page.click('button[type="submit"]')
            
            # Fill claim form
            await page.fill('#claim_amount', str(claim_data['amount']))
            await page.fill('#incident_date', claim_data['date'])
            await page.fill('#description', claim_data['description'])
            
            # Upload documents
            for doc in claim_data['documents']:
                await page.set_input_files('#file_upload', doc['path'])
            
            # Submit
            await page.click('#submit_claim')
            
            # Get confirmation number
            confirmation = await page.inner_text('.confirmation-number')
            
            await browser.close()
            
            return {
                "success": True,
                "confirmation_number": confirmation,
                "timestamp": datetime.utcnow().isoformat()
            }
```

**Success Criteria:**
- âœ… Claim auto-filled with 90%+ accuracy
- âœ… User review time < 2 minutes
- âœ… Submission success rate > 95%
- âœ… Support for top 5 card issuers

**Estimated Time:** 6-8 weeks  
**Owner:** Integrations + Full-stack Team

**Revenue Impact:** This feature alone could be a premium tier ($10-20/month)

---

## Architectural Improvements

### 4.1 Move from Monolith to Service-Oriented

**Current:** Everything in one Next.js app + Python API

**Target:** Microservices architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Next.js   â”‚  (Frontend + API Routes)
â”‚   Frontend  â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
       â”‚              â”‚              â”‚             â”‚
â”Œâ”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â–¼â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â–¼â”€â”€â”€â”€â”
â”‚  MCP Server â”‚  â”‚  Auth  â”‚  â”‚  Claims   â”‚  â”‚ Webhooksâ”‚
â”‚  (Python)   â”‚  â”‚  Serviceâ”‚  â”‚  Service  â”‚  â”‚ Service â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚              â”‚              â”‚             â”‚
       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                      â”‚
               â”Œâ”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”
               â”‚   Supabase  â”‚
               â”‚  (Database) â”‚
               â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Migration Plan:**
1. Extract auth logic to separate service
2. Extract claim processing to separate service
3. Keep MCP server for tool execution
4. Use API gateway (Kong/Tyk) for routing

**Benefits:**
- Independent scaling of services
- Team ownership boundaries
- Easier to test and deploy
- Technology flexibility

**Estimated Time:** 8-12 weeks  
**Owner:** Architecture Team

---

### 4.2 Event-Driven Architecture

**Current:** Synchronous request-response

**Target:** Event-driven with message queue

```
Transaction Created â†’ Queue â†’ [
  â†’ Coverage Analysis Service
  â†’ Fraud Detection Service
  â†’ Recommendation Service
  â†’ Analytics Service
]
```

**Implementation:**
```python
# Use Amazon SQS, RabbitMQ, or Supabase Realtime

# Publisher
async def publish_event(event_type: str, data: dict):
    await queue.publish(
        exchange='claimwise',
        routing_key=event_type,
        body=json.dumps(data)
    )

# Consumer
@queue.consumer('transaction.created')
async def handle_transaction_created(message):
    transaction = json.loads(message.body)
    
    # Analyze coverage
    await analyze_coverage(transaction)
    
    # Check for recommendations
    await check_recommendations(transaction)
    
    # Log for analytics
    await log_transaction_event(transaction)
```

**Benefits:**
- Better reliability (retries, dead letter queues)
- Horizontal scaling
- Loose coupling
- Easier to add new event handlers

**Estimated Time:** 4-6 weeks  
**Owner:** Backend Team

---

## Technology Stack Recommendations

### Current Stack
- âœ… Next.js (good choice)
- âœ… Supabase (good for MVP)
- âœ… Python FastMCP (good for MCP protocol)
- âš ï¸ No caching layer
- âš ï¸ No message queue
- âš ï¸ No monitoring

### Recommended Additions

**Caching:** Redis Cloud (free tier available)
**Message Queue:** Supabase Realtime or AWS SQS
**Monitoring:** Axiom or Datadog
**Error Tracking:** Sentry
**Analytics:** PostHog or Amplitude
**CDN:** Vercel Edge (already included)
**Search:** Supabase pgvector (already using) or Algolia

### Infrastructure

**Development:**
- Local: Docker Compose
- Preview: Vercel Preview Deployments

**Production:**
- Frontend: Vercel (Next.js)
- Backend: Railway or Fly.io (Python)
- Database: Supabase (Postgres)
- Cache: Redis Cloud
- Queue: AWS SQS or Supabase
- CDN: Vercel Edge Network

**Cost Estimate (MVP):**
- Vercel Pro: $20/month
- Supabase Pro: $25/month
- Railway: $20-50/month
- Redis: Free (1GB)
- Monitoring: $20-50/month
- **Total: ~$100-150/month**

---

## Risk Analysis

### Technical Risks

| Risk | Likelihood | Impact | Mitigation |
|------|------------|--------|------------|
| Build system upgrade breaks app | Medium | High | Test in isolated branch, have rollback plan |
| Performance degradation at scale | High | High | Load testing, caching, auto-scaling |
| Third-party API rate limits | Medium | Medium | Implement retry logic, cache aggressively |
| Data loss | Low | Critical | Automated backups, point-in-time recovery |
| Security breach | Medium | Critical | Regular audits, bug bounty program |

### Business Risks

| Risk | Likelihood | Impact | Mitigation |
|------|------------|--------|------------|
| Carrier blocking automated submissions | Medium | High | Build relationships with issuers, offer manual fallback |
| Competitors copy features | High | Medium | Speed of execution, network effects |
| Regulatory compliance issues | Low | High | Legal review, compliance team |
| User adoption slower than expected | Medium | High | Strong onboarding, referral program |

---

## Success Metrics

### Phase 1 (Foundation)
- âœ… Frontend loads without errors
- âœ… Health checks return 200
- âœ… Rate limiting active
- âœ… Zero security vulnerabilities (Snyk scan)

### Phase 2 (Scale)
- âœ… P95 response time < 500ms
- âœ… Uptime > 99.5%
- âœ… Error rate < 1%
- âœ… Zero data loss incidents

### Phase 3 (Differentiation)
- âœ… 1000+ active users
- âœ… 500+ claims filed through platform
- âœ… Average claim filing time < 10 minutes (vs 2-3 hours manual)
- âœ… Recommendation acceptance rate > 40%
- âœ… NPS score > 50

---

## Resource Requirements

### Team Composition

**Phase 1 (2 people, 2 weeks):**
- 1 Senior Full-stack Engineer
- 1 DevOps Engineer

**Phase 2 (3 people, 2 weeks):**
- 1 Backend Engineer
- 1 Frontend Engineer
- 1 DevOps Engineer

**Phase 3 (5 people, 8 weeks):**
- 2 Full-stack Engineers
- 1 ML Engineer
- 1 Integration Engineer
- 1 Product Manager

**Ongoing (3 people):**
- 1 Full-stack Engineer (maintenance)
- 1 Customer Support Engineer
- 1 Product Manager

---

## Conclusion

Claimwise has **strong fundamentals** but needs **immediate technical intervention** to reach production readiness. The 3-phase roadmap provides a clear path from prototype to market leader:

**Phase 1** fixes critical blockers (2 weeks)  
**Phase 2** prepares for scale (2 weeks)  
**Phase 3** builds competitive moat (8-12 weeks)

**Total Timeline: 12-16 weeks to market-leading position**

**Investment Required:**
- Engineering: ~$150-200K (team salaries for 4 months)
- Infrastructure: ~$500-1000 (MVP hosting)
- Tools/Services: ~$2-3K (monitoring, analytics)
- **Total: ~$153-204K**

**Expected ROI:**
- Time to market: 4 months
- Initial user base: 1000-2000 users
- Revenue potential: $10-20K MRR (freemium model)
- Break-even: 6-9 months post-launch

The technical foundation is solid. With focused execution, Claimwise can become **the default coverage copilot for credit card users**.

---

**Document Version:** 1.0  
**Last Updated:** 2026-02-05  
**Next Review:** After Phase 1 completion
